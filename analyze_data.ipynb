{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3fb53e",
   "metadata": {},
   "source": [
    "# Analyze Data\n",
    "### Extract data infromation that can help us decide how to design the model and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253df947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e1863",
   "metadata": {},
   "source": [
    "## Verify true fps match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "719204c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fps: 30.0\n",
      "test fps: 30.0\n",
      "val fps: 30.0\n"
     ]
    }
   ],
   "source": [
    "# Load videos verify fps match \n",
    "cap_train = cv2.VideoCapture('./data/images/train/train.mp4')\n",
    "cap_test = cv2.VideoCapture('./data/images/test/test.mp4')\n",
    "cap_val = cv2.VideoCapture('./data/images/val/val.mp4')\n",
    "\n",
    "print(f\"train fps: {cap_train.get(cv2.CAP_PROP_FPS)}\")\n",
    "print(f\"test fps: {cap_test.get(cv2.CAP_PROP_FPS)}\")\n",
    "print(f\"val fps: {cap_val.get(cv2.CAP_PROP_FPS)}\")\n",
    "\n",
    "cap_train.release()\n",
    "cap_test.release()\n",
    "cap_val.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4fd04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_H = 640\n",
    "RES_W = 640 \n",
    "FPS = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef50929",
   "metadata": {},
   "source": [
    "## Check annotations, instances, occurences, count (ground truth statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd4587",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5cf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract necessary data from json\n",
    "def load_json_data(path):\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c3e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_BOLT = 1\n",
    "ID_NUT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c90605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training frames:  7200\n"
     ]
    }
   ],
   "source": [
    "# 1 - bolt, 2 - nut \n",
    "train_data = load_json_data('./data/annotations/instances_train.json')\n",
    "train_annotations = train_data['annotations']\n",
    "no_frames = len(train_data['images'])\n",
    "print('Number of training frames: ',no_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01c2ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frames with bolt instance (repetition allowed)\n",
    "frames_with_bolt = [instance['image_id'] for instance in train_annotations if instance['category_id'] == ID_BOLT]\n",
    "# Frames with nut instance (repetition allowed)\n",
    "frames_with_nut = [instance['image_id'] for instance in train_annotations if instance['category_id'] == ID_NUT]\n",
    "# Frames with nut both\n",
    "frames_with_both = np.intersect1d(frames_with_bolt, frames_with_nut, assume_unique=False)\n",
    "\n",
    "frames_with_bolt, frames_with_bolt_count = np.unique(frames_with_bolt, return_counts=True)\n",
    "frames_with_nut, frames_with_nut_count = np.unique(frames_with_nut, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247334f",
   "metadata": {},
   "source": [
    "### Percentage of videos with Bolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "358ad4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True frame = frame containint the object of interest \n",
      "\n",
      "Percentage of frames with bolts: 92%\n",
      "Bolts per true frame: 2.23 \n",
      "\n",
      "Percentage of frames with nuts: 50%\n",
      "Nuts per true frame: 1.00 \n",
      "\n",
      "Percentage of frames with both: 47%\n"
     ]
    }
   ],
   "source": [
    "print(\"True frame = frame containint the object of interest \\n\")\n",
    "print(f'Percentage of frames with bolts: {round(len(frames_with_bolt)*100/no_frames)}%')\n",
    "print(\"Bolts per true frame: {:.2f} \\n\".format(np.mean(frames_with_bolt_count)))\n",
    "\n",
    "print(f'Percentage of frames with nuts: {round(len(frames_with_nut)*100/no_frames)}%')\n",
    "print(\"Nuts per true frame: {:.2f} \\n\".format(np.mean(frames_with_nut_count)))\n",
    "\n",
    "print(f'Percentage of frames with both: {round(len(frames_with_both)*100/no_frames)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ad606",
   "metadata": {},
   "source": [
    "### Analyze labeling quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e12da6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35df3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the bbox around the images \n",
    "orig_dir = 'C:/Users/mirza/Desktop/stroma-tracking/data/experiment/frames/train'\n",
    "target_dir = 'C:/Users/mirza/Desktop/stroma-tracking/data/experiment/frames_with_boxes/train'\n",
    "LIMIT = 10\n",
    "\n",
    "for i, annotation in enumerate(train_annotations):\n",
    "    image_id = annotation['image_id']\n",
    "    bbox = annotation['bbox']\n",
    "    xmin = int(bbox[0])\n",
    "    ymin = int(bbox[1])\n",
    "    xmax = int(bbox[0] + bbox[2])\n",
    "    ymax = int(bbox[1] + bbox[3])\n",
    "    #print(xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    if os.path.exists('{}/{:04d}.jpg'.format(target_dir,image_id)):\n",
    "        image = cv2.imread('{}/{:04d}.jpg'.format(target_dir,image_id))\n",
    "    else:\n",
    "        image = cv2.imread('{}/{:04d}.jpg'.format(orig_dir,image_id))\n",
    "        \n",
    "    _ = cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "    cv2.imwrite('{}/{:04d}.jpg'.format(target_dir,image_id), image)\n",
    "    \n",
    "    if i > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03053f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python predict_on_video.py ./data/images/test/test.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
